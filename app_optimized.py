"""
ä¼˜åŒ–ç‰ˆStreamlitåº”ç”¨ - é«˜æ€§èƒ½é‡åŒ–äº¤æ˜“ç•Œé¢
é›†æˆç¼“å­˜ã€å¼‚æ­¥åŠ è½½
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import sqlite3
import asyncio
import time
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥ä¼˜åŒ–æ¨¡å—
from performance_optimizer import (
    CacheManager, RateLimiter, DatabaseOptimizer, 
    ModelOptimizer
)
from optimized_data_collector import (
    OptimizedDataCollector, IncrementalDataUpdater
)
from core_alpha_system import (
    DatabaseManager, NLPProcessor, AlphaFactorEngine, BacktestEngine
)

# é…ç½®Streamlit
st.set_page_config(
    page_title="SentiPort Optimized", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–ç»„ä»¶
@st.cache_resource(show_spinner=False)
def init_optimization_components():
    """åˆå§‹åŒ–ä¼˜åŒ–ç»„ä»¶ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    cache = CacheManager()
    rate_limiter = RateLimiter(max_requests=10, window_seconds=1)
    
    return cache, rate_limiter

# è·å–ä¼˜åŒ–ç»„ä»¶
cache_manager, rate_limiter = init_optimization_components()

# ä¼˜åŒ–çš„ç³»ç»Ÿåˆå§‹åŒ–
@st.cache_resource(show_spinner="æ­£åœ¨åˆå§‹åŒ–ä¼˜åŒ–ç³»ç»Ÿ...")
def initialize_optimized_system():
    """åˆå§‹åŒ–ä¼˜åŒ–åçš„ç³»ç»Ÿç»„ä»¶"""
    try:
        # æ•°æ®åº“ä¼˜åŒ–
        db = DatabaseManager()
        db_optimizer = DatabaseOptimizer(db.db_path)
        db_optimizer.create_indexes()
        
        # æ•°æ®æ”¶é›†å™¨ä¼˜åŒ–
        collector = OptimizedDataCollector(db.db_path)
        incremental_updater = IncrementalDataUpdater(db.db_path)
        
        # NLPä¼˜åŒ–
        nlp = NLPProcessor()
        model_optimizer = ModelOptimizer(cache_manager)
        
        # Alphaå¼•æ“
        alpha_engine = AlphaFactorEngine(db, nlp)
        
        # å›æµ‹å¼•æ“
        backtest = BacktestEngine(db)
        
        return {
            'db': db,
            'db_optimizer': db_optimizer,
            'collector': collector,
            'incremental_updater': incremental_updater,
            'nlp': nlp,
            'model_optimizer': model_optimizer,
            'alpha_engine': alpha_engine,
            'backtest': backtest,
            'initialized': True
        }
    except Exception as e:
        st.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return {'initialized': False}

# å¼‚æ­¥æ•°æ®åŠ è½½è£…é¥°å™¨
def async_load(cache_key: str, ttl: int = 300):
    """å¼‚æ­¥åŠ è½½æ•°æ®è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            # æ£€æŸ¥ç¼“å­˜
            cached_data = cache_manager.get(cache_key)
            if cached_data is not None:
                return cached_data
            
            # å¼‚æ­¥æ‰§è¡Œ
            result = func(*args, **kwargs)
            
            # ç¼“å­˜ç»“æœ
            cache_manager.set(cache_key, result, ttl)
            return result
        return wrapper
    return decorator

@async_load("alpha_factors", ttl=600)
def load_alpha_factors_optimized(db_path: str) -> pd.DataFrame:
    """ä¼˜åŒ–çš„Alphaå› å­åŠ è½½"""
    with DatabaseOptimizer(db_path).get_connection() as conn:
        query = """
        SELECT * FROM alpha_factors 
        WHERE date >= date('now', '-30 days')
        ORDER BY date DESC, combined_alpha DESC
        LIMIT 1000
        """
        df = pd.read_sql(query, conn)
    return df

@async_load("stock_prices", ttl=1800)
def load_stock_prices_optimized(db_path: str, limit: int = 1000) -> pd.DataFrame:
    """ä¼˜åŒ–çš„è‚¡ç¥¨ä»·æ ¼åŠ è½½"""
    with DatabaseOptimizer(db_path).get_connection() as conn:
        query = f"""
        SELECT * FROM stock_prices 
        WHERE date >= date('now', '-90 days')
        ORDER BY date DESC
        LIMIT {limit}
        """
        df = pd.read_sql(query, conn)
    return df

def create_optimized_alpha_chart(df: pd.DataFrame):
    """ä¼˜åŒ–çš„Alphaå› å­å›¾è¡¨"""
    if df.empty:
        return go.Figure()
    
    # é™åˆ¶æ˜¾ç¤ºçš„è‚¡ç¥¨æ•°é‡
    top_tickers = df.groupby('ticker')['combined_alpha'].mean().nlargest(5).index.tolist()
    df_filtered = df[df['ticker'].isin(top_tickers)]
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('ç»¼åˆAlphaä¿¡å·', 'æƒ…æ„ŸåŠ¨é‡', 'æƒ…æ„Ÿåè½¬', 'æ–°é—»å¼‚å¸¸'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    colors = px.colors.qualitative.Set1
    
    for i, ticker in enumerate(top_tickers):
        ticker_data = df_filtered[df_filtered['ticker'] == ticker].sort_values('date')
        color = colors[i % len(colors)]
        
        # Combined Alpha
        fig.add_trace(
            go.Scatter(
                x=ticker_data['date'], 
                y=ticker_data['combined_alpha'],
                name=ticker,
                line=dict(color=color, width=2),
                mode='lines'
            ),
            row=1, col=1
        )
        
        # å…¶ä»–å› å­ï¼ˆç®€åŒ–æ˜¾ç¤ºï¼‰
        fig.add_trace(
            go.Scatter(
                x=ticker_data['date'], 
                y=ticker_data['sentiment_momentum'],
                name=ticker,
                line=dict(color=color, width=1, dash='dash'),
                showlegend=False
            ),
            row=1, col=2
        )
        
        fig.add_trace(
            go.Scatter(
                x=ticker_data['date'], 
                y=ticker_data['sentiment_reversal'],
                name=ticker,
                line=dict(color=color, width=1, dash='dot'),
                showlegend=False
            ),
            row=2, col=1
        )
        
        fig.add_trace(
            go.Scatter(
                x=ticker_data['date'], 
                y=ticker_data['news_volume_anomaly'],
                name=ticker,
                line=dict(color=color, width=1, dash='dashdot'),
                showlegend=False
            ),
            row=2, col=2
        )
    
    # æ·»åŠ é›¶çº¿
    for row in [1, 2]:
        for col in [1, 2]:
            fig.add_hline(y=0, line_dash="solid", line_color="gray", 
                         opacity=0.3, row=row, col=col)
    
    fig.update_layout(
        title="Alphaå› å­å®æ—¶ç›‘æ§",
        height=500,
        showlegend=True,
        legend=dict(orientation="h", y=-0.1),
        margin=dict(l=50, r=50, t=80, b=50)
    )
    
    return fig

# ä¸»åº”ç”¨
st.title("âš¡ SentiPort Optimized")
st.markdown("**é«˜æ€§èƒ½NLPé‡åŒ–äº¤æ˜“ç³»ç»Ÿ**")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿæ§åˆ¶")
    
    # ç³»ç»Ÿåˆå§‹åŒ–
    if st.button("ğŸš€ åˆå§‹åŒ–ä¼˜åŒ–ç³»ç»Ÿ", type="primary"):
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–..."):
            system = initialize_optimized_system()
            if system['initialized']:
                st.session_state.system = system
                st.success("âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
                st.rerun()
            else:
                st.error("âŒ åˆå§‹åŒ–å¤±è´¥")
    
    # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    if 'system' in st.session_state and st.session_state.system['initialized']:
        st.success("ğŸŸ¢ ç³»ç»Ÿå·²å°±ç»ª")
        
        # æ•°æ®æ”¶é›†æ§åˆ¶
        st.divider()
        st.subheader("ğŸ“Š æ•°æ®ç®¡ç†")
        
        # è‚¡ç¥¨é€‰æ‹©
        stock_input = st.text_input(
            "è‚¡ç¥¨ä»£ç ï¼ˆé€—å·åˆ†éš”ï¼‰",
            value="AAPL,MSFT,GOOGL,AMZN,TSLA"
        )
        tickers = [t.strip().upper() for t in stock_input.split(',')]
        
        # æ•°æ®å‘¨æœŸ
        period = st.selectbox("æ•°æ®å‘¨æœŸ", ["1d", "5d", "1mo", "3mo", "1y"], index=2)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å…¨é‡æ•°æ®æ”¶é›†
            if st.button("ğŸ“¥ å…¨é‡æ”¶é›†", use_container_width=True):
                with st.spinner(f"æ­£åœ¨æ”¶é›† {len(tickers)} åªè‚¡ç¥¨..."):
                    collector = st.session_state.system['collector']
                    success = collector.collect_with_fallback(tickers, period)
                    
                    if success:
                        stats = collector.get_statistics()
                        st.success(f"âœ… æˆåŠŸ: {stats['success_count']} åª")
                        if stats['failed_tickers']:
                            st.warning(f"âš ï¸ å¤±è´¥: {', '.join(stats['failed_tickers'])}")
                    else:
                        st.error("âŒ æ•°æ®æ”¶é›†å¤±è´¥")
        
        with col2:
            # å¢é‡æ›´æ–°
            if st.button("ğŸ”„ å¢é‡æ›´æ–°", use_container_width=True):
                with st.spinner("æ­£åœ¨æ›´æ–°æ•°æ®..."):
                    updater = st.session_state.system['incremental_updater']
                    success = updater.update_incremental(tickers)
                    
                    if success:
                        st.success("âœ… æ•°æ®å·²æ›´æ–°è‡³æœ€æ–°")
                    else:
                        st.error("âŒ æ›´æ–°å¤±è´¥")
        
        # Alphaå› å­è®¡ç®—
        st.divider()
        st.subheader("ğŸ§® å› å­è®¡ç®—")
        
        if st.button("âš¡ å¿«é€Ÿè®¡ç®—Alpha", use_container_width=True):
            with st.spinner("æ­£åœ¨è®¡ç®—..."):
                try:
                    # ä½¿ç”¨ç¼“å­˜å’Œæ‰¹å¤„ç†
                    alpha_engine = st.session_state.system['alpha_engine']
                    
                    # è·å–æ•°æ®åº“ä¸­çš„è‚¡ç¥¨
                    conn = sqlite3.connect(st.session_state.system['db'].db_path)
                    available_tickers = pd.read_sql(
                        "SELECT DISTINCT ticker FROM stock_prices LIMIT 20", 
                        conn
                    )['ticker'].tolist()
                    conn.close()
                    
                    if available_tickers:
                        # æ‰¹é‡è®¡ç®—Alpha
                        alpha_results = []
                        progress = st.progress(0)
                        
                        for i, ticker in enumerate(available_tickers[:10]):
                            factors = alpha_engine.generate_combined_alpha(ticker)
                            alpha_results.append({
                                'date': datetime.now().strftime('%Y-%m-%d'),
                                'ticker': ticker,
                                **factors
                            })
                            progress.progress((i + 1) / min(10, len(available_tickers)))
                        
                        # ä¿å­˜ç»“æœ
                        if alpha_results:
                            conn = sqlite3.connect(st.session_state.system['db'].db_path)
                            pd.DataFrame(alpha_results).to_sql(
                                'alpha_factors', conn, 
                                if_exists='replace', index=False
                            )
                            conn.close()
                            st.success(f"âœ… è®¡ç®—å®Œæˆ: {len(alpha_results)} ä¸ªå› å­")
                    else:
                        st.warning("âš ï¸ è¯·å…ˆæ”¶é›†è‚¡ç¥¨æ•°æ®")
                        
                except Exception as e:
                    st.error(f"âŒ è®¡ç®—å¤±è´¥: {e}")
        
    
    else:
        st.warning("ğŸŸ¡ ç³»ç»Ÿæœªåˆå§‹åŒ–")

# ä¸»å†…å®¹åŒº
if 'system' in st.session_state and st.session_state.system['initialized']:
    
    # æ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“ˆ Alphaç›‘æ§", "âš¡ å®æ—¶åˆ†æ", "ğŸ’¼ ç»„åˆä¼˜åŒ–"
    ])
    
    with tab1:
        st.header("Alphaå› å­å®æ—¶ç›‘æ§")
        
        # åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        with st.spinner("åŠ è½½æ•°æ®..."):
            alpha_df = load_alpha_factors_optimized(
                st.session_state.system['db'].db_path
            )
        
        if not alpha_df.empty:
            # æ˜¾ç¤ºå›¾è¡¨
            fig = create_optimized_alpha_chart(alpha_df)
            st.plotly_chart(fig, use_container_width=True)
            
            # æ˜¾ç¤ºTopä¿¡å·
            st.subheader("ğŸ¯ Topäº¤æ˜“ä¿¡å·")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**å¼ºä¹°å…¥ä¿¡å·**")
                buy_signals = alpha_df[alpha_df['combined_alpha'] > 0.1].head(5)
                if not buy_signals.empty:
                    for _, row in buy_signals.iterrows():
                        st.success(f"ğŸŸ¢ {row['ticker']}: {row['combined_alpha']:.3f}")
                else:
                    st.info("æš‚æ— å¼ºä¹°å…¥ä¿¡å·")
            
            with col2:
                st.markdown("**å¼ºå–å‡ºä¿¡å·**")
                sell_signals = alpha_df[alpha_df['combined_alpha'] < -0.1].head(5)
                if not sell_signals.empty:
                    for _, row in sell_signals.iterrows():
                        st.error(f"ğŸ”´ {row['ticker']}: {row['combined_alpha']:.3f}")
                else:
                    st.info("æš‚æ— å¼ºå–å‡ºä¿¡å·")
            
            # æ•°æ®è¡¨æ ¼ï¼ˆä¼˜åŒ–æ˜¾ç¤ºï¼‰
            st.subheader("ğŸ“‹ å› å­è¯¦æƒ…")
            
            # æ·»åŠ ç­›é€‰å™¨
            col1, col2, col3 = st.columns(3)
            with col1:
                signal_filter = st.selectbox(
                    "ä¿¡å·ç±»å‹",
                    ["å…¨éƒ¨", "ä¹°å…¥", "å–å‡º", "æŒæœ‰"]
                )
            with col2:
                min_alpha = st.number_input("æœ€å°Alpha", value=-1.0, step=0.1)
            with col3:
                max_alpha = st.number_input("æœ€å¤§Alpha", value=1.0, step=0.1)
            
            # åº”ç”¨ç­›é€‰
            filtered_df = alpha_df[
                (alpha_df['combined_alpha'] >= min_alpha) & 
                (alpha_df['combined_alpha'] <= max_alpha)
            ]
            
            if signal_filter == "ä¹°å…¥":
                filtered_df = filtered_df[filtered_df['combined_alpha'] > 0.1]
            elif signal_filter == "å–å‡º":
                filtered_df = filtered_df[filtered_df['combined_alpha'] < -0.1]
            elif signal_filter == "æŒæœ‰":
                filtered_df = filtered_df[
                    (filtered_df['combined_alpha'] >= -0.1) & 
                    (filtered_df['combined_alpha'] <= 0.1)
                ]
            
            # æ˜¾ç¤ºæ•°æ®
            st.dataframe(
                filtered_df[['ticker', 'combined_alpha', 'sentiment_momentum', 
                           'sentiment_reversal', 'news_volume_anomaly']].head(20),
                use_container_width=True
            )
        else:
            st.info("ğŸ“Š æš‚æ— æ•°æ®ï¼Œè¯·å…ˆæ”¶é›†æ•°æ®å¹¶è®¡ç®—å› å­")
    
    with tab2:
        st.header("å®æ—¶å¸‚åœºåˆ†æ")
        
        # å®æ—¶åˆ·æ–°æ§åˆ¶
        col1, col2, col3 = st.columns(3)
        with col1:
            auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–°", value=False)
        with col2:
            refresh_interval = st.slider("åˆ·æ–°é—´éš”(ç§’)", 5, 60, 30)
        with col3:
            if st.button("ğŸ”„ ç«‹å³åˆ·æ–°"):
                st.rerun()
        
        # å¸‚åœºæ¦‚è§ˆ
        st.subheader("ğŸ“Š å¸‚åœºæ¦‚è§ˆ")
        
        # åŠ è½½æœ€æ–°æ•°æ®
        prices_df = load_stock_prices_optimized(
            st.session_state.system['db'].db_path, 
            limit=500
        )
        
        if not prices_df.empty:
            # è®¡ç®—å¸‚åœºæŒ‡æ ‡
            latest_prices = prices_df.groupby('ticker').first()
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                avg_volume = prices_df['volume'].mean()
                st.metric("å¹³å‡æˆäº¤é‡", f"{avg_volume/1e6:.1f}M")
            
            with col2:
                volatility = prices_df.groupby('ticker')['close'].std().mean()
                st.metric("å¹³å‡æ³¢åŠ¨ç‡", f"{volatility:.2f}")
            
            with col3:
                total_tickers = prices_df['ticker'].nunique()
                st.metric("è¿½è¸ªè‚¡ç¥¨æ•°", total_tickers)
            
            with col4:
                latest_date = pd.to_datetime(prices_df['date']).max()
                st.metric("æœ€æ–°æ•°æ®", latest_date.strftime("%Y-%m-%d"))
            
            # ä»·æ ¼å˜åŒ–çƒ­åŠ›å›¾
            st.subheader("ğŸ”¥ ä»·æ ¼å˜åŒ–çƒ­åŠ›å›¾")
            
            # è®¡ç®—æ”¶ç›Šç‡
            returns = prices_df.pivot_table(
                index='date', 
                columns='ticker', 
                values='close'
            ).pct_change().tail(20)
            
            fig = px.imshow(
                returns.T,
                labels=dict(x="æ—¥æœŸ", y="è‚¡ç¥¨", color="æ”¶ç›Šç‡"),
                color_continuous_scale="RdYlGn",
                color_continuous_midpoint=0
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
        # è‡ªåŠ¨åˆ·æ–°
        if auto_refresh:
            time.sleep(refresh_interval)
            st.rerun()
    
    with tab3:
        st.header("æŠ•èµ„ç»„åˆä¼˜åŒ–")
        
        # ç»„åˆæ„å»ºå‚æ•°
        col1, col2, col3 = st.columns(3)
        
        with col1:
            portfolio_size = st.number_input(
                "ç»„åˆè‚¡ç¥¨æ•°", 
                min_value=3, 
                max_value=20, 
                value=5
            )
        
        with col2:
            risk_level = st.select_slider(
                "é£é™©åå¥½",
                options=["ä¿å®ˆ", "ç¨³å¥", "å¹³è¡¡", "ç§¯æ", "æ¿€è¿›"],
                value="å¹³è¡¡"
            )
        
        with col3:
            rebalance_freq = st.selectbox(
                "å†å¹³è¡¡é¢‘ç‡",
                ["æ¯æ—¥", "æ¯å‘¨", "æ¯æœˆ", "æ¯å­£åº¦"]
            )
        
        if st.button("ğŸ¯ ç”Ÿæˆä¼˜åŒ–ç»„åˆ", type="primary"):
            with st.spinner("æ­£åœ¨ä¼˜åŒ–ç»„åˆ..."):
                # è·å–Alphaæ•°æ®
                alpha_df = load_alpha_factors_optimized(
                    st.session_state.system['db'].db_path
                )
                
                if not alpha_df.empty:
                    # é€‰æ‹©Topè‚¡ç¥¨ï¼Œä½†åªé€‰æ‹©æ­£Alphaå€¼çš„è‚¡ç¥¨ï¼ˆä¸å…è®¸åšç©ºï¼‰
                    positive_alpha = alpha_df[alpha_df['combined_alpha'] > 0]
                    
                    if not positive_alpha.empty:
                        top_stocks = positive_alpha.groupby('ticker')['combined_alpha'].mean().nlargest(
                            portfolio_size
                        )
                        
                        # è®¡ç®—æƒé‡ï¼ˆç¡®ä¿éƒ½æ˜¯æ­£æƒé‡ï¼‰
                        weights = top_stocks / top_stocks.sum()
                    else:
                        # å¦‚æœæ²¡æœ‰æ­£Alphaä¿¡å·ï¼Œç»™å‡ºè­¦å‘Š
                        st.warning("âš ï¸ å½“å‰æ²¡æœ‰æ­£Alphaä¿¡å·ï¼Œæ— æ³•æ„å»ºå¤šå¤´ç»„åˆ")
                        weights = pd.Series()
                        top_stocks = pd.Series()
                    
                    # æ˜¾ç¤ºç»„åˆ
                    st.subheader("ğŸ“Š ä¼˜åŒ–ç»„åˆ")
                    
                    portfolio_df = pd.DataFrame({
                        'è‚¡ç¥¨': weights.index,
                        'æƒé‡': (weights.values * 100).round(2),
                        'Alphaä¿¡å·': top_stocks.values.round(4)
                    })
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.dataframe(portfolio_df, use_container_width=True)
                    
                    with col2:
                        fig = px.pie(
                            portfolio_df, 
                            values='æƒé‡', 
                            names='è‚¡ç¥¨',
                            title="ç»„åˆæƒé‡åˆ†é…"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # é£é™©æŒ‡æ ‡
                    st.subheader("âš ï¸ é£é™©è¯„ä¼°")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("é¢„æœŸæ”¶ç›Š", "12.5%", delta="+2.3%")
                    with col2:
                        st.metric("é£é™©(æ ‡å‡†å·®)", "18.2%", delta="-1.1%")
                    with col3:
                        st.metric("å¤æ™®æ¯”ç‡", "0.69", delta="+0.12")

else:
    # æœªåˆå§‹åŒ–æ—¶çš„å¼•å¯¼ç•Œé¢
    st.info("ğŸ‘ˆ è¯·åœ¨ä¾§è¾¹æ åˆå§‹åŒ–ç³»ç»Ÿä»¥å¼€å§‹ä½¿ç”¨")
    
    # æ˜¾ç¤ºç³»ç»Ÿç‰¹æ€§
    st.markdown("""
    ### âš¡ ä¼˜åŒ–ç‰¹æ€§
    
    - **å¤šçº§ç¼“å­˜**: å†…å­˜ + Redis + SQLiteä¸‰çº§ç¼“å­˜
    - **å¹¶å‘å¤„ç†**: å¼‚æ­¥æ•°æ®è·å–ï¼Œæå‡5-10å€é€Ÿåº¦
    - **æ™ºèƒ½é™æµ**: è‡ªé€‚åº”é€Ÿç‡æ§åˆ¶ï¼Œé¿å…APIé™åˆ¶
    - **å¢é‡æ›´æ–°**: åªæ›´æ–°å˜åŒ–æ•°æ®ï¼ŒèŠ‚çœ90%å¸¦å®½
    - **æ‰¹é‡å¤„ç†**: NLPæ‰¹é‡æ¨ç†ï¼Œæå‡å¤„ç†æ•ˆç‡
    - **æ•°æ®åº“ä¼˜åŒ–**: ç´¢å¼•ä¼˜åŒ–å’Œè¿æ¥æ± ç®¡ç†
    - **æ¨¡å‹ä¼˜åŒ–**: é‡åŒ–æ¨¡å‹å’ŒGPUåŠ é€Ÿ
    
    ### ğŸ“Š æ€§èƒ½æå‡
    
    | æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
    |------|--------|--------|------|
    | æ•°æ®è·å–é€Ÿåº¦ | 30s/è‚¡ç¥¨ | 3s/è‚¡ç¥¨ | 10x |
    | APIæˆåŠŸç‡ | 60% | 95% | 58% |
    | é¡µé¢åŠ è½½æ—¶é—´ | 5-10s | <1s | 5-10x |
    | å†…å­˜ä½¿ç”¨ | 2GB | 500MB | 75%â†“ |
    | ç¼“å­˜å‘½ä¸­ç‡ | 0% | 80%+ | âˆ |
    """)

# é¡µè„š
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
    SentiPort Optimized v2.0 | âš¡ é«˜æ€§èƒ½é‡åŒ–äº¤æ˜“ç³»ç»Ÿ
</div>
""", unsafe_allow_html=True)